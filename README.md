# ğŸ§‘â€ğŸ¨ Portrait Animation Evaluation

This repository provides a unified evaluation pipeline for comparing multiple portrait animation models under consistent settings.


## ğŸ› ï¸ Build Environment

```bash
conda create -n evaluation python=3.11
conda activate evaluation

pip install -r requirements.txt
```


## ğŸ“ Directory Structure

- `config/`: Configuration files for each model (`.yaml`)
- `checkpoint/`: Pretrained model checkpoints
- `data/`: Evaluation dataset  
  (expected structure: `data/test/{video_name}/{frame}.jpg`)
- `scripts/`: Model-specific run scripts and GT (ground truth) saving scripts
- `modules/`: Inference logic per model
- `eval/`: Output directory for evaluation results  
  (saved in `eval/{reconstruction, animate}/{model_name}`)


## ğŸš€ Run Inference

```bash
python -m scripts/<model> --mode reconstruction --config config/<model>.yaml --checkpoint checkpoint/<model>.pth
python -m scripts/<model> --mode animate --config config/<model>.yaml --checkpoint checkpoint/<model>.pth
```


## ğŸ”§ Dataset Configuration

When running in `animate` mode, make sure the following value is set in your YAML config file:

```bash
dataset_params:
  is_full: False
```


## ğŸ’¾ Result Format

```bash
eval/
â”œâ”€â”€ reconstruction/
â”‚   â”œâ”€â”€ fomm/
â”‚   â”‚   â”œâ”€â”€ <name1>/000.png, 001.png, ...
â”‚   â”‚   â””â”€â”€ compare/<name1>.gif
â”‚   â”œâ”€â”€ fvv/
â”‚   â”œâ”€â”€ lia/
â”‚   â””â”€â”€ gt/
â””â”€â”€ animate/
    â”œâ”€â”€ fomm/
    â”‚   â”œâ”€â”€ driving-source/000.png, 001.png, ...
    â”‚   â””â”€â”€ compare/driving-source.gif
    â”œâ”€â”€ fvv/
    â”œâ”€â”€ lia/
    â””â”€â”€ gt/
        â”œâ”€â”€ source/
        â””â”€â”€ driving/
```


## ğŸ”— References

- [First Order Motion Model for Image Animation](https://github.com/AliaksandrSiarohin/first-order-model), presented at NIPS 2019.
- [One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing](https://github.com/zhanglonghao1992/One-Shot_Free-View_Neural_Talking_Head_Synthesis), presented at CVPR 2021.
- [Latent Image Animator: Learning to Animate Images via Latent Space Navigation](https://github.com/wyhsirius/LIA), presented at ICLR 2022.
